{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78594606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\yadav\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from transformers import DataCollatorWithPadding\n",
    "from datasets import Dataset\n",
    "\n",
    "# Optional: Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff1f6db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../../data/train.csv\", encoding='latin1')\n",
    "test_df = pd.read_csv(\"../../data/test.csv\", encoding='latin1')\n",
    "\n",
    "train_df.drop(columns = ['textID','selected_text','Time of Tweet','Age of User','Country','Population -2020','Land Area (Km²)','Density (P/Km²)'], inplace=True)\n",
    "test_df.drop(columns = ['textID','Time of Tweet','Age of User','Country','Population -2020','Land Area (Km²)','Density (P/Km²)'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebe01ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27481, 2)\n",
      "(4815, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d6769a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "train_df.dropna(subset=['text', 'sentiment'], inplace=True)\n",
    "test_df.dropna(subset=['text', 'sentiment'], inplace=True)\n",
    "\n",
    "train_df['label'] = train_df['sentiment'].map(label2id).astype(int)\n",
    "test_df['label'] = test_df['sentiment'].map(label2id).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efa00c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['text'] = train_df['text'].astype(str)\n",
    "test_df['text'] = test_df['text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cca8d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sentiment",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "int32",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "df59728b-cb82-4542-9bd0-dbd4707ec13c",
       "rows": [
        [
         "0",
         " I`d have responded, if I were going",
         "neutral",
         "1"
        ],
        [
         "1",
         " Sooo SAD I will miss you here in San Diego!!!",
         "negative",
         "0"
        ],
        [
         "2",
         "my boss is bullying me...",
         "negative",
         "0"
        ],
        [
         "3",
         " what interview! leave me alone",
         "negative",
         "0"
        ],
        [
         "4",
         " Sons of ****, why couldn`t they put them on the releases we already bought",
         "negative",
         "0"
        ],
        [
         "5",
         "http://www.dothebouncy.com/smf - some shameless plugging for the best Rangers forum on earth",
         "neutral",
         "1"
        ],
        [
         "6",
         "2am feedings for the baby are fun when he is all smiles and coos",
         "positive",
         "2"
        ],
        [
         "7",
         "Soooo high",
         "neutral",
         "1"
        ],
        [
         "8",
         " Both of you",
         "neutral",
         "1"
        ],
        [
         "9",
         " Journey!? Wow... u just became cooler.  hehe... (is that possible!?)",
         "positive",
         "2"
        ],
        [
         "10",
         " as much as i love to be hopeful, i reckon the chances are minimal =P i`m never gonna get my cake and stuff",
         "neutral",
         "1"
        ],
        [
         "11",
         "I really really like the song Love Story by Taylor Swift",
         "positive",
         "2"
        ],
        [
         "12",
         "My Sharpie is running DANGERously low on ink",
         "negative",
         "0"
        ],
        [
         "13",
         "i want to go to music tonight but i lost my voice.",
         "negative",
         "0"
        ],
        [
         "14",
         "test test from the LG enV2",
         "neutral",
         "1"
        ],
        [
         "15",
         "Uh oh, I am sunburned",
         "negative",
         "0"
        ],
        [
         "16",
         " S`ok, trying to plot alternatives as we speak *sigh*",
         "negative",
         "0"
        ],
        [
         "17",
         "i`ve been sick for the past few days  and thus, my hair looks wierd.  if i didnt have a hat on it would look... http://tinyurl.com/mnf4kw",
         "negative",
         "0"
        ],
        [
         "18",
         "is back home now      gonna miss every one",
         "negative",
         "0"
        ],
        [
         "19",
         "Hes just not that into you",
         "neutral",
         "1"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 20
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2am feedings for the baby are fun when he is a...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Soooo high</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Both of you</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Journey!? Wow... u just became cooler.  hehe....</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>as much as i love to be hopeful, i reckon the...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I really really like the song Love Story by Ta...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>My Sharpie is running DANGERously low on ink</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>i want to go to music tonight but i lost my vo...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>test test from the LG enV2</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Uh oh, I am sunburned</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>S`ok, trying to plot alternatives as we speak...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>i`ve been sick for the past few days  and thus...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>is back home now      gonna miss every one</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Hes just not that into you</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text sentiment  label\n",
       "0                 I`d have responded, if I were going   neutral      1\n",
       "1       Sooo SAD I will miss you here in San Diego!!!  negative      0\n",
       "2                           my boss is bullying me...  negative      0\n",
       "3                      what interview! leave me alone  negative      0\n",
       "4    Sons of ****, why couldn`t they put them on t...  negative      0\n",
       "5   http://www.dothebouncy.com/smf - some shameles...   neutral      1\n",
       "6   2am feedings for the baby are fun when he is a...  positive      2\n",
       "7                                          Soooo high   neutral      1\n",
       "8                                         Both of you   neutral      1\n",
       "9    Journey!? Wow... u just became cooler.  hehe....  positive      2\n",
       "10   as much as i love to be hopeful, i reckon the...   neutral      1\n",
       "11  I really really like the song Love Story by Ta...  positive      2\n",
       "12       My Sharpie is running DANGERously low on ink  negative      0\n",
       "13  i want to go to music tonight but i lost my vo...  negative      0\n",
       "14                         test test from the LG enV2   neutral      1\n",
       "15                              Uh oh, I am sunburned  negative      0\n",
       "16   S`ok, trying to plot alternatives as we speak...  negative      0\n",
       "17  i`ve been sick for the past few days  and thus...  negative      0\n",
       "18         is back home now      gonna miss every one  negative      0\n",
       "19                         Hes just not that into you   neutral      1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4f82f900",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    train_df['text'], train_df['label'], test_size=0.1, stratify=train_df['label'], random_state=42\n",
    ")\n",
    "\n",
    "train_dataset = Dataset.from_dict({'text': train_texts.tolist(), 'label': train_labels.tolist()})\n",
    "val_dataset = Dataset.from_dict({'text': val_texts.tolist(), 'label': val_labels.tolist()})\n",
    "test_dataset = Dataset.from_dict({'text': test_df['text'].tolist(), 'label': test_df['label'].tolist()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b6b3566d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yadav\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adcaf226597d49e2977d761c3d32af8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/24732 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5af628d3b434957aac25ace3fcdd6a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2748 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d3118d145784409ac9eb707b6a053b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3534 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example['text'], truncation=True)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d3b5b381",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=3,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3892a029",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    logging_dir=\"./logs\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d867193",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yadav\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e15bb9d2606b432797a4ecc874791ec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4638 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6928, 'learning_rate': 1.7843898231996552e-05, 'epoch': 0.32}\n",
      "{'loss': 0.5542, 'learning_rate': 1.56877964639931e-05, 'epoch': 0.65}\n",
      "{'loss': 0.5335, 'learning_rate': 1.3531694695989652e-05, 'epoch': 0.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05d8187c505c41b389bdf053e92a2790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/86 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5303931832313538, 'eval_runtime': 37.4475, 'eval_samples_per_second': 73.383, 'eval_steps_per_second': 2.297, 'epoch': 1.0}\n",
      "{'loss': 0.417, 'learning_rate': 1.1375592927986202e-05, 'epoch': 1.29}\n",
      "{'loss': 0.4, 'learning_rate': 9.219491159982752e-06, 'epoch': 1.62}\n",
      "{'loss': 0.3958, 'learning_rate': 7.0633893919793015e-06, 'epoch': 1.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f4a026aacec40c4893371e6a8998e55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/86 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5413020253181458, 'eval_runtime': 37.2234, 'eval_samples_per_second': 73.825, 'eval_steps_per_second': 2.31, 'epoch': 2.0}\n",
      "{'loss': 0.3058, 'learning_rate': 4.907287623975852e-06, 'epoch': 2.26}\n",
      "{'loss': 0.2858, 'learning_rate': 2.751185855972402e-06, 'epoch': 2.59}\n",
      "{'loss': 0.2676, 'learning_rate': 5.950840879689522e-07, 'epoch': 2.91}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69f72a13423f4608a583e749c25d9b2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/86 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6308823823928833, 'eval_runtime': 37.6754, 'eval_samples_per_second': 72.939, 'eval_steps_per_second': 2.283, 'epoch': 3.0}\n",
      "{'train_runtime': 3054.126, 'train_samples_per_second': 24.294, 'train_steps_per_second': 1.519, 'train_loss': 0.42354091728180837, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4638, training_loss=0.42354091728180837, metrics={'train_runtime': 3054.126, 'train_samples_per_second': 24.294, 'train_steps_per_second': 1.519, 'train_loss': 0.42354091728180837, 'epoch': 3.0})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3392818a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "971c5ff43aa8420d8ad876e44d7acba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/111 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.78      0.79      1001\n",
      "     neutral       0.77      0.74      0.75      1430\n",
      "    positive       0.80      0.85      0.83      1103\n",
      "\n",
      "    accuracy                           0.79      3534\n",
      "   macro avg       0.79      0.79      0.79      3534\n",
      "weighted avg       0.79      0.79      0.79      3534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(test_dataset)\n",
    "preds = np.argmax(predictions.predictions, axis=1)\n",
    "true = np.array(test_dataset['label'])\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true, preds, target_names=[\"negative\", \"neutral\", \"positive\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf743fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
